{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607df4ab-4956-44c6-a809-7920b68d6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import *\n",
    "from PIL import *\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e68df1-2f54-428b-b415-ce990cf6381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1 = cv2.VideoCapture(\"homework_1_test_video.mp4\")\n",
    "video_2 = cv2.VideoCapture(\"聖稜-雪山的脊樑©.mp4\")\n",
    "\n",
    "fps = video_1.get(cv2.CAP_PROP_FPS) \n",
    "frames = video_1.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_width_1 = int(video_1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height_1 = int(video_1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_width_2 = int(video_2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height_2 = int(video_2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "default_video_1 = cv2.VideoWriter('default_video_1.mp4', fourcc, fps, (frame_width_1, frame_height_1))\n",
    "default_video_2 = cv2.VideoWriter('default_video_2.mp4', fourcc, fps, (frame_width_2, frame_height_2))\n",
    "\n",
    "while video_1.isOpened() and video_2.isOpened():\n",
    "    ret_1, frame_1 = video_1.read()\n",
    "    default_video_1.write(frame_1)\n",
    "    ret_2, frame_2 = video_2.read()\n",
    "    default_video_2.write(frame_2)\n",
    "    if not ret_1 or not ret_2:\n",
    "        break\n",
    "        \n",
    "video_1.release()\n",
    "video_2.release()\n",
    "default_video_1.release()\n",
    "default_video_2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16a64af-6756-4108-b229-6308701bdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_level_mapping(image):\n",
    "    image_tensor = torch.tensor(image).float() / 255.0\n",
    "    channels = image_tensor.permute(2, 0, 1) \n",
    "    equalized_channels = []\n",
    "    for channel in channels:\n",
    "        channel_hist = torch.histc(channel, bins=256, min=0, max=1)\n",
    "        cdf = channel_hist.cumsum(0)  \n",
    "        cdf = (cdf - cdf.min()) / (cdf.max() - cdf.min())  \n",
    "        equalized_channel = cdf[(channel * 255).long()]\n",
    "        equalized_channels.append(equalized_channel)\n",
    "    equalized_image = torch.stack(equalized_channels, dim=0).permute(1, 2, 0) * 255.0\n",
    "    return equalized_image.byte().numpy()\n",
    "    \n",
    "def high_pass_filter(image):\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "    channels, height, width = image_tensor.shape\n",
    "    f_transform = torch.fft.fft2(image_tensor)\n",
    "    f_transform_shifted = torch.fft.fftshift(f_transform)\n",
    "    r = 30\n",
    "    crow, ccol = height // 2, width // 2\n",
    "    y, x = torch.meshgrid(torch.arange(height), torch.arange(width), indexing='ij')\n",
    "    mask = torch.ones((channels, height, width), dtype=torch.float32)\n",
    "    for i in range(channels):\n",
    "        mask[i, (x - ccol) ** 2 + (y - crow) ** 2 <= r ** 2] = 0\n",
    "    f_transform_filtered = f_transform_shifted * mask\n",
    "    f_transform_ishifted = torch.fft.ifftshift(f_transform_filtered)\n",
    "    image = torch.fft.ifft2(f_transform_ishifted)\n",
    "    image = torch.abs(image) * 255.0\n",
    "    image = image.permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    channels = cv2.split(image)\n",
    "    channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "    return cv2.merge(channels)\n",
    "\n",
    "def rgb_to_hsv(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03aabfa7-bcd7-4141-b751-d4aa70924898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': False, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2mp41', 'encoder': 'Lavf58.76.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1920, 1080], 'bitrate': 41605, 'fps': 30.0, 'codec_name': 'mpeg4', 'profile': '(Simple Profile)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 9.9, 'bitrate': 41607, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'mpeg4', 'video_profile': '(Simple Profile)', 'video_size': [1920, 1080], 'video_bitrate': 41605, 'video_fps': 30.0, 'video_duration': 9.9, 'video_n_frames': 297}\n",
      "C:\\Users\\useraux\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i default_video_1.mp4 -loglevel error -f image2pipe -vf scale=1920:1080 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': False, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2mp41', 'encoder': 'Lavf58.76.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 1008, 'fps': 30.0, 'codec_name': 'mpeg4', 'profile': '(Simple Profile)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 9.93, 'bitrate': 1010, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'mpeg4', 'video_profile': '(Simple Profile)', 'video_size': [640, 360], 'video_bitrate': 1008, 'video_fps': 30.0, 'video_duration': 9.93, 'video_n_frames': 297}\n",
      "C:\\Users\\useraux\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i default_video_2.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video processed_video_1.mp4.\n",
      "MoviePy - Writing video processed_video_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready processed_video_1.mp4\n",
      "MoviePy - Building video processed_video_2.mp4.\n",
      "MoviePy - Writing video processed_video_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready processed_video_2.mp4\n",
      "MoviePy - Building video processed_video_3.mp4.\n",
      "MoviePy - Writing video processed_video_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready processed_video_3.mp4\n",
      "MoviePy - Building video processed_video_4.mp4.\n",
      "MoviePy - Writing video processed_video_4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready processed_video_4.mp4\n"
     ]
    }
   ],
   "source": [
    "default_video_1 = VideoFileClip(\"default_video_1.mp4\")\n",
    "default_video_2 = VideoFileClip(\"default_video_2.mp4\")\n",
    "\n",
    "video_1 = []\n",
    "video_2 = []\n",
    "video_3 = []\n",
    "video_4 = []\n",
    "\n",
    "for frame in default_video_1.iter_frames(fps=default_video_1.fps, dtype=\"uint8\"):\n",
    "    processed_frame_1 = gray_level_mapping(frame)\n",
    "    processed_frame_2 = high_pass_filter(frame)\n",
    "    video_1.append(processed_frame_1)\n",
    "    video_2.append(processed_frame_2)\n",
    "\n",
    "for frame in default_video_2.iter_frames(fps=default_video_2.fps, dtype=\"uint8\"):\n",
    "    processed_frame_3 = histogram_equalization(frame)\n",
    "    processed_frame_4 = rgb_to_hsv(frame)\n",
    "    video_3.append(processed_frame_3)\n",
    "    video_4.append(processed_frame_4)\n",
    "\n",
    "processed_video_1 = ImageSequenceClip(video_1, fps=default_video_1.fps)\n",
    "processed_video_2 = ImageSequenceClip(video_2, fps=default_video_1.fps)\n",
    "processed_video_3 = ImageSequenceClip(video_3, fps=default_video_2.fps)\n",
    "processed_video_4 = ImageSequenceClip(video_4, fps=default_video_2.fps)\n",
    "\n",
    "processed_video_1.write_videofile(\"processed_video_1.mp4\", codec=\"libx264\")\n",
    "processed_video_2.write_videofile(\"processed_video_2.mp4\", codec=\"libx264\")\n",
    "processed_video_3.write_videofile(\"processed_video_3.mp4\", codec=\"libx264\")\n",
    "processed_video_4.write_videofile(\"processed_video_4.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405a7d9-2aeb-46e6-8144-42e6445e266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = default_video_1.resized(height=360)\n",
    "clip2 = processed_video_1.resized(height=360)\n",
    "clip3 = processed_video_2.resized(height=360)\n",
    "clip4 = default_video_2.resized(height=360)\n",
    "clip5 = processed_video_3.resized(height=360)\n",
    "clip6 = processed_video_4.resized(height=360)\n",
    "\n",
    "merged_video = clips_array([\n",
    "    [clip1, clip2, clip3],\n",
    "    [clip4, clip5, clip6]\n",
    "])\n",
    "\n",
    "merged_video.write_videofile(\"merged_video.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ea2a1-8430-4487-a2e8-391155f592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TexttoSpeech:\n",
    "    def __init__(self):\n",
    "        self.engine = pyttsx3.init()\n",
    "        voices = self.engine.getProperty('voices') \n",
    "        self.engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "    def text_to_speech(self,message):\n",
    "        self.engine.say(message) \n",
    "        self.engine.runAndWait()\n",
    "    \n",
    "    def text_to_mp3(self,message,mp3file):\n",
    "        self.engine.save_to_file(message, mp3file)\n",
    "        self.engine.runAndWait()\n",
    "        \n",
    "ts = TexttoSpeech()\n",
    "\n",
    "narration_texts='''哈囉，這是機器視覺作業的報告影片\n",
    "讓我來逐一介紹每個影像所應用的處理技術\n",
    "首先，最上一排是作業測試影片\n",
    "這排使用pytorch的函式庫來處理\n",
    "左上是原始影片\n",
    "中上是灰階映射後的結果\n",
    "右上是高通濾波器處理後的結果\n",
    "接著，下面這排是聖稜-雪山的脊樑\n",
    "這排使用open cv的函式庫來處理\n",
    "左下是原始影片\n",
    "中下是直方圖等化後的結果\n",
    "右下是顏色空間從RGB轉換為HSV的結果\n",
    "感謝您的觀看！'''\n",
    "      \n",
    "lines = [msg.strip() for msg in narration_texts.split('\\n') if len(msg)>0]\n",
    "speech= []\n",
    "for i,msg in enumerate(lines):\n",
    "    ts.text_to_mp3(msg,'subtitle-voiceover-{:04d}.mp3'.format(i))    \n",
    "    speech.append(AudioFileClip('subtitle-voiceover-{:04d}.mp3'.format(i)))\n",
    "        \n",
    "duration       = np.array([0]+[s.duration for s in speech])   \n",
    "cumduration    = np.cumsum(duration)\n",
    "total_duration = int(cumduration[-1])+4    \n",
    "\n",
    "generator = lambda txt: TextClip('msjh.ttc', txt, font_size=32, color='white')\n",
    "subtitles = SubtitlesClip([((cumduration[i],cumduration[i+1]),s) for i,s in enumerate(lines)], make_textclip=generator, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03479099-ffad-4327-953b-f417a6192a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = AudioFileClip(\"calm background.mp3\")\n",
    "bgm = bgm.subclipped(bgm.duration-total_duration).with_volume_scaled(0.15)\n",
    "clip = VideoFileClip(\"merged_video.mp4\")\n",
    "clip = clip.with_speed_scaled(clip.duration/total_duration,total_duration)\n",
    "\n",
    "final_clip = CompositeVideoClip([clip, subtitles.with_position(('center','bottom'))])\n",
    "final_clip = final_clip.with_audio(CompositeAudioClip([bgm,concatenate_audioclips(speech)]))\n",
    "final_clip.write_videofile(\"final_video.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
